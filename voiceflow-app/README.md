# VoiceFlow - From thought to text in seconds

A modern, production-ready voice notes application built with Next.js 14, featuring AI-powered transcription and intelligent text processing.

## âœ¨ Features

- **ğŸ™ï¸ Real-time Voice Recording** - High-quality recording with live waveform visualization
- **ğŸ“ File Upload Support** - Drag & drop for MP3, WAV, M4A, WebM files
- **ğŸ¤– AI Transcription** - OpenAI Whisper integration for accurate speech-to-text
- **ğŸ§  Smart Text Processing** - Anthropic Claude for text cleaning, summaries, and key points
- **ğŸ“± Responsive Design** - Mobile-first approach with smooth animations
- **ğŸŒ™ Dark/Light Mode** - Theme switching with system preference detection
- **ğŸ” Secure Authentication** - Google & GitHub OAuth integration
- **ğŸ“Š Recording Management** - Search, organize, and export your recordings
- **ğŸš€ Production Ready** - Docker support, Vercel deployment, and optimized builds

## ğŸ› ï¸ Tech Stack

- **Frontend**: Next.js 14, TypeScript, Tailwind CSS, Framer Motion
- **UI Components**: shadcn/ui, Radix UI
- **Authentication**: NextAuth.js
- **Database**: Prisma ORM (SQLite dev / PostgreSQL prod)
- **AI Services**: OpenAI Whisper API, Anthropic Claude API
- **Deployment**: Vercel, Docker

## ğŸš€ Quick Start

### Prerequisites

- Node.js 18+
- npm or yarn
- OpenAI API key
- Anthropic API key

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/voiceflow-app.git
   cd voiceflow-app
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Set up environment variables**
   ```bash
   cp .env.example .env.local
   ```
   
   Fill in your environment variables:
   ```env
   # Database
   DATABASE_URL="file:./dev.db"
   
   # NextAuth.js
   NEXTAUTH_URL="http://localhost:3000"
   NEXTAUTH_SECRET="your-secret-here"
   
   # OAuth Providers
   GOOGLE_CLIENT_ID="your-google-client-id"
   GOOGLE_CLIENT_SECRET="your-google-client-secret"
   GITHUB_CLIENT_ID="your-github-client-id"
   GITHUB_CLIENT_SECRET="your-github-client-secret"
   
   # AI APIs
   OPENAI_API_KEY="your-openai-api-key"
   ANTHROPIC_API_KEY="your-anthropic-api-key"
   ```

4. **Set up the database**
   ```bash
   npx prisma generate
   npx prisma db push
   ```

5. **Start the development server**
   ```bash
   npm run dev
   ```

6. **Open your browser**
   Navigate to [http://localhost:3000](http://localhost:3000)

## ğŸ“ Project Structure

```
voiceflow-app/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ app/                    # Next.js 14 App Router
â”‚   â”‚   â”œâ”€â”€ api/               # API routes
â”‚   â”‚   â”œâ”€â”€ auth/              # Authentication pages
â”‚   â”‚   â”œâ”€â”€ dashboard/         # Main dashboard
â”‚   â”‚   â””â”€â”€ globals.css        # Global styles
â”‚   â”œâ”€â”€ components/            # React components
â”‚   â”‚   â”œâ”€â”€ ui/               # shadcn/ui components
â”‚   â”‚   â”œâ”€â”€ voice/            # Voice recording components
â”‚   â”‚   â”œâ”€â”€ upload/           # File upload components
â”‚   â”‚   â”œâ”€â”€ dashboard/        # Dashboard components
â”‚   â”‚   â”œâ”€â”€ auth/             # Authentication components
â”‚   â”‚   â”œâ”€â”€ theme/            # Theme components
â”‚   â”‚   â””â”€â”€ layout/           # Layout components
â”‚   â”œâ”€â”€ hooks/                # Custom React hooks
â”‚   â”œâ”€â”€ lib/                  # Utility libraries
â”‚   â””â”€â”€ types/                # TypeScript type definitions
â”œâ”€â”€ prisma/                   # Database schema and migrations
â”œâ”€â”€ public/                   # Static assets
â””â”€â”€ ...config files
```

## ğŸ”§ Configuration

### OAuth Setup

1. **Google OAuth**
   - Go to [Google Cloud Console](https://console.cloud.google.com)
   - Create a new project or select existing
   - Enable Google+ API
   - Create OAuth 2.0 credentials
   - Add authorized redirect URIs: `http://localhost:3000/api/auth/callback/google`

2. **GitHub OAuth**
   - Go to [GitHub Settings > Developer settings > OAuth Apps](https://github.com/settings/developers)
   - Create a new OAuth App
   - Set Authorization callback URL: `http://localhost:3000/api/auth/callback/github`

### API Keys

1. **OpenAI API Key**
   - Visit [OpenAI Platform](https://platform.openai.com)
   - Create an account and generate an API key
   - Ensure you have access to the Whisper API

2. **Anthropic API Key**
   - Visit [Anthropic Console](https://console.anthropic.com)
   - Create an account and generate an API key
   - Ensure you have access to Claude models

## ğŸš¢ Deployment

### Vercel (Recommended)

1. **Connect your repository to Vercel**
2. **Set environment variables** in the Vercel dashboard
3. **Deploy** - Vercel will automatically build and deploy your app

### Docker

1. **Build the image**
   ```bash
   docker build -t voiceflow-app .
   ```

2. **Run with Docker Compose**
   ```bash
   docker-compose up -d
   ```

### Production Database

For production, switch from SQLite to PostgreSQL:

1. **Update your DATABASE_URL**
   ```env
   DATABASE_URL="postgresql://username:password@host:port/database"
   ```

2. **Run migrations**
   ```bash
   npx prisma migrate deploy
   ```

## ğŸ”’ Security Features

- **Authentication**: Secure OAuth implementation with NextAuth.js
- **Data Validation**: Input validation and sanitization
- **CORS Protection**: Configured API route protection
- **Environment Variables**: Sensitive data stored securely
- **Type Safety**: Full TypeScript implementation

## ğŸ“ API Documentation

### Transcription Endpoint
```typescript
POST /api/transcribe
Content-Type: multipart/form-data

Body: FormData with 'audio' file

Response: {
  transcript: string
  duration: number
  language: string
  wordCount: number
}
```

### Text Processing Endpoint
```typescript
POST /api/process-text
Content-Type: application/json

Body: {
  transcript: string
}

Response: {
  title: string
  cleanedText: string
  summary: string
  keyPoints: string[]
  tags: string[]
}
```

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/amazing-feature`
3. Commit your changes: `git commit -m 'Add amazing feature'`
4. Push to the branch: `git push origin feature/amazing-feature`
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ†˜ Support

- ğŸ“§ Email: support@voiceflow.app
- ğŸ› Issues: [GitHub Issues](https://github.com/yourusername/voiceflow-app/issues)
- ğŸ’¬ Discussions: [GitHub Discussions](https://github.com/yourusername/voiceflow-app/discussions)

## ğŸ™ Acknowledgments

- [Next.js](https://nextjs.org/) - The React Framework for Production
- [OpenAI](https://openai.com/) - Whisper API for speech-to-text
- [Anthropic](https://anthropic.com/) - Claude API for text processing
- [shadcn/ui](https://ui.shadcn.com/) - Beautiful UI components
- [Vercel](https://vercel.com/) - Deployment platform

---

Made with â¤ï¸ by the VoiceFlow team